{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    x = np.random.random(10).reshape(1, -1)\n",
    "    y = np.zeros((1, 2))\n",
    "    y[0, np.random.randint(2)] = 1\n",
    "    return {'features': x, 'labels': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(10000)).map(lambda i: make_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[38] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128, 78)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "data_cnt = data.count()\n",
    "n_batch = data_cnt // batch_size\n",
    "\n",
    "data_cnt, batch_size, n_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ratios = [batch_size / data_cnt] * int(math.ceil(data_cnt / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concate_data(x, y):\n",
    "    dataset = {}\n",
    "    for f in ['features', 'labels']:\n",
    "        dataset[f] = np.concatenate((x[f], y[f]), axis=0)\n",
    "    return dataset\n",
    "\n",
    "def next_batch_rdd_maker(data_rdd, batch_size, epoch_limit=None):\n",
    "    data_cnt = data_rdd.count()\n",
    "    per_batch_ratios = [batch_size / data_cnt] * int(math.ceil(data_cnt / batch_size))\n",
    "    def next_batch():\n",
    "        current_epoch = 0\n",
    "        while True:\n",
    "            current_epoch += 1\n",
    "            print('{} epoch starts!'.format(current_epoch))\n",
    "            if epoch_limit is not None and current_epoch > epoch_limit: \n",
    "                break \n",
    "            batches = data_rdd.randomSplit(per_batch_ratios)\n",
    "            for batch in batches:\n",
    "                dataset = batch.reduce(concate_data)\n",
    "                yield dataset['features'], dataset['labels']\n",
    "    return next_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch starts!\n",
      "(138, 10) (138, 2)\n",
      "[[ 0.27177158  0.09338174  0.92922062  0.36163314  0.73897763  0.92920518\n",
      "   0.38691253  0.72721468  0.70133953  0.69426265]\n",
      " [ 0.08568551  0.73242113  0.05241102  0.52411065  0.65283585  0.63729227\n",
      "   0.52427596  0.17664183  0.87864636  0.12582561]\n",
      " [ 0.07634491  0.65796259  0.95377654  0.58873708  0.9534006   0.80688632\n",
      "   0.6015825   0.00614666  0.88245379  0.34886694]\n",
      " [ 0.25666931  0.72250646  0.04606842  0.40685677  0.24097207  0.49946615\n",
      "   0.25957772  0.60548888  0.36035151  0.86844128]\n",
      " [ 0.2342444   0.78365248  0.17697823  0.41353043  0.2105957   0.65231435\n",
      "   0.28149155  0.62406179  0.65004654  0.09867522]]\n",
      "run n_batch 1\n",
      "(121, 10) (121, 2)\n",
      "[[ 0.66221035  0.61361795  0.40311533  0.05496737  0.43807495  0.26238466\n",
      "   0.38744381  0.95097486  0.95174443  0.54242663]\n",
      " [ 0.35378197  0.92210629  0.60737942  0.38028022  0.18423603  0.36786244\n",
      "   0.4846854   0.22169417  0.91627218  0.08162744]\n",
      " [ 0.62853929  0.28698232  0.93687132  0.44806423  0.96212175  0.7931239\n",
      "   0.95335576  0.89066838  0.59923601  0.04041059]\n",
      " [ 0.90830626  0.38788767  0.11742257  0.00230048  0.20610149  0.65750481\n",
      "   0.57817892  0.90141437  0.72665803  0.07939947]\n",
      " [ 0.79403583  0.55200365  0.84412701  0.44228133  0.27688986  0.09466044\n",
      "   0.90560747  0.20886619  0.30833592  0.67600503]]\n",
      "run n_batch 2\n",
      "(127, 10) (127, 2)\n",
      "[[ 0.67079955  0.14103012  0.84139908  0.70086247  0.13759066  0.80508907\n",
      "   0.2562575   0.16814623  0.56638002  0.18499757]\n",
      " [ 0.37795412  0.98271697  0.04106253  0.25759815  0.69771608  0.67508989\n",
      "   0.22434113  0.16025249  0.95835055  0.60345267]\n",
      " [ 0.9978628   0.84375231  0.80784464  0.52265826  0.29030889  0.71713864\n",
      "   0.9491749   0.48470311  0.97479699  0.23986928]\n",
      " [ 0.25367122  0.07442179  0.60915621  0.97271486  0.95628736  0.39885945\n",
      "   0.65558885  0.4282091   0.45080081  0.78634348]\n",
      " [ 0.9034706   0.55045237  0.86961569  0.87132701  0.98123306  0.34754632\n",
      "   0.81984399  0.06695607  0.80998145  0.73870331]]\n",
      "run n_batch 3\n"
     ]
    }
   ],
   "source": [
    "next_batch = next_batch_rdd_maker(data, batch_size, epoch_limit=2)\n",
    "\n",
    "i = 0\n",
    "for X_batch, Y_batch in next_batch():\n",
    "    print(X_batch.shape, Y_batch.shape)\n",
    "    print(X_batch[0:5])\n",
    "    #print(Y_batch[0:5])\n",
    "    i += 1\n",
    "    print(\"run n_batch {}\".format(i))\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0\n",
      "(129, 10)\n",
      "[[ 0.48635838  0.98921333  0.91002174  0.10785167  0.52518158  0.67597269\n",
      "   0.43819769  0.29130476  0.20639989  0.43597756]\n",
      " [ 0.18104039  0.5238487   0.9512993   0.32673712  0.15810872  0.58777654\n",
      "   0.27607022  0.24480085  0.11503928  0.26171353]\n",
      " [ 0.95290001  0.50672181  0.83296424  0.39207746  0.00743004  0.4126532\n",
      "   0.98544884  0.26875377  0.20756379  0.50919635]\n",
      " [ 0.66578263  0.08125266  0.11051948  0.87752661  0.19079544  0.31896252\n",
      "   0.87644394  0.76199772  0.85945378  0.87912064]\n",
      " [ 0.77659382  0.18806926  0.06847789  0.82411926  0.54146513  0.75857833\n",
      "   0.85752319  0.53143017  0.03749443  0.56385056]]\n",
      "k: 32\n",
      "(128, 10)\n",
      "[[ 0.49769865  0.35492167  0.73923198  0.54776133  0.53627974  0.7961213\n",
      "   0.7117204   0.8003712   0.05167417  0.4436853 ]\n",
      " [ 0.64673222  0.89587558  0.14287286  0.30088512  0.93246049  0.83798712\n",
      "   0.04624728  0.35743467  0.67240937  0.23058261]\n",
      " [ 0.47284257  0.22737204  0.6183083   0.83636114  0.8050909   0.04081084\n",
      "   0.70676419  0.45593846  0.16608987  0.14655997]\n",
      " [ 0.52449132  0.70988636  0.85256209  0.11670944  0.39496605  0.03292494\n",
      "   0.91477302  0.69781601  0.2557124   0.76631506]\n",
      " [ 0.74546485  0.15175941  0.75576121  0.43486155  0.83549432  0.21118689\n",
      "   0.79831013  0.86425577  0.9656746   0.82994058]]\n",
      "k: 48\n",
      "(128, 10)\n",
      "[[ 0.82972015  0.16254953  0.36836501  0.25458249  0.21833937  0.08306407\n",
      "   0.87521431  0.11546578  0.68691037  0.321716  ]\n",
      " [ 0.37961545  0.44466635  0.38234195  0.9550841   0.20640493  0.36382786\n",
      "   0.51258511  0.76333157  0.83060301  0.74724513]\n",
      " [ 0.67561337  0.39820348  0.43245742  0.80402336  0.94363125  0.28304747\n",
      "   0.32094612  0.96694644  0.73593672  0.03886082]\n",
      " [ 0.99722869  0.62292006  0.29443106  0.5578095   0.48325422  0.59798523\n",
      "   0.33966712  0.38336839  0.42347287  0.68170006]\n",
      " [ 0.94925202  0.26597367  0.78811223  0.87614762  0.7615243   0.50327116\n",
      "   0.65615944  0.31223594  0.72607863  0.32226663]]\n",
      "k: 8\n",
      "(129, 10)\n",
      "[[ 0.73674575  0.20795857  0.43767429  0.83257607  0.21812148  0.29092021\n",
      "   0.57629529  0.79753692  0.83940177  0.96417769]\n",
      " [ 0.13291878  0.93692682  0.51533738  0.1773671   0.93654951  0.02491364\n",
      "   0.3048832   0.04128835  0.10706949  0.24902403]\n",
      " [ 0.16665464  0.12714994  0.17728532  0.37900713  0.91089515  0.35541864\n",
      "   0.26945188  0.877056    0.56298233  0.48274952]\n",
      " [ 0.06383666  0.24902673  0.03826424  0.84963316  0.743904    0.76830291\n",
      "   0.26594424  0.69035295  0.16318822  0.50211573]\n",
      " [ 0.94412977  0.40032145  0.91211096  0.8417723   0.95989058  0.36315211\n",
      "   0.36732907  0.74908426  0.62969684  0.20669011]]\n"
     ]
    }
   ],
   "source": [
    "group_rdd = data \\\n",
    "    .sortBy(lambda x: np.random.random()) \\\n",
    "    .zipWithIndex() \\\n",
    "    .map(lambda x: (x[1]%n_batch, x[0])) \\\n",
    "    .groupByKey() \\\n",
    "    .map(lambda d: (d[0], reduce(concate_data, d[1]))) \\\n",
    "    .persist()\n",
    "\n",
    "keys = group_rdd.keys().collect()\n",
    "\n",
    "i = 0\n",
    "for k in keys:\n",
    "    batch = group_rdd \\\n",
    "        .filter(lambda d: d[0] == k) \\\n",
    "        .map(lambda d: d[1]) \\\n",
    "        .collect()[0]\n",
    "    print('k: {}'.format(k))\n",
    "    print(batch['features'].shape)\n",
    "    print(batch['features'][:5])\n",
    "    i += 1\n",
    "    if i > 3:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_data = {'features': [], 'labels': []}\n",
    "\n",
    "def seq(data_arr, data):\n",
    "    for f in ['features', 'labels']:\n",
    "        data_arr[f].append(data[f])\n",
    "    return data_arr\n",
    "\n",
    "def comp(data_arr1, data_arr2):\n",
    "    result = {}\n",
    "    for f in ['features', 'labels']:\n",
    "        result[f] = data_arr1[f] + data_arr2[f]\n",
    "    return result\n",
    "\n",
    "def concate(data_arr):\n",
    "    result = {}\n",
    "    for f in ['features', 'labels']:\n",
    "        result[f] = np.concatenate(data_arr[f], axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===epoch 1===\n",
      "\n",
      "batch_key: 0\n",
      "--features--\n",
      "(129, 10)\n",
      "[[ 0.00990009  0.5423004   0.49345573  0.99874654  0.37192966  0.61709061\n",
      "   0.75635913  0.2223606   0.19015739  0.42220939]\n",
      " [ 0.63431151  0.61970168  0.83143894  0.23898155  0.67763027  0.03630547\n",
      "   0.09853002  0.07944521  0.99443968  0.85384792]]\n",
      "--labels--\n",
      "(129, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "\n",
      "batch_key: 32\n",
      "--features--\n",
      "(128, 10)\n",
      "[[ 0.69581008  0.29972252  0.71522633  0.64813835  0.22056874  0.53705215\n",
      "   0.40476738  0.02412487  0.45648007  0.19110131]\n",
      " [ 0.40190421  0.99927003  0.28505162  0.59169471  0.32652689  0.79453915\n",
      "   0.06946079  0.46745301  0.89838656  0.76408965]]\n",
      "--labels--\n",
      "(128, 2)\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "===epoch 2===\n",
      "\n",
      "batch_key: 0\n",
      "--features--\n",
      "(129, 10)\n",
      "[[ 0.40414736  0.51240878  0.25732977  0.34385521  0.72576452  0.90960537\n",
      "   0.72805053  0.50107734  0.23724009  0.35689232]\n",
      " [ 0.52275893  0.14185051  0.40293815  0.4839048   0.47405422  0.23736155\n",
      "   0.75616067  0.01124846  0.11510762  0.61535321]]\n",
      "--labels--\n",
      "(129, 2)\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "\n",
      "batch_key: 32\n",
      "--features--\n",
      "(128, 10)\n",
      "[[ 0.45487297  0.68490973  0.04434827  0.28823794  0.69016133  0.03929546\n",
      "   0.08759227  0.89275372  0.84706805  0.8597856 ]\n",
      " [ 0.51952928  0.10553054  0.49016877  0.8742238   0.20594193  0.37415156\n",
      "   0.12934911  0.6541869   0.55267815  0.82165776]]\n",
      "--labels--\n",
      "(128, 2)\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    print('===epoch {}==='.format(epoch+1))\n",
    "    \n",
    "    group_rdd = data \\\n",
    "        .sortBy(lambda x: np.random.random()) \\\n",
    "        .zipWithIndex() \\\n",
    "        .map(lambda x: (x[1]%n_batch, x[0])) \\\n",
    "        .aggregateByKey(init_data, seq, comp) \\\n",
    "        .mapValues(concate) \\\n",
    "        .persist()\n",
    "    \n",
    "    i = 0\n",
    "    for k in group_rdd.keys().collect():\n",
    "        batch = group_rdd \\\n",
    "            .filter(lambda d: d[0] == k) \\\n",
    "            .map(lambda d: d[1]) \\\n",
    "            .collect()[0]\n",
    "        print('\\nbatch_key: {}'.format(k))\n",
    "        print('--features--')\n",
    "        print(batch['features'].shape)\n",
    "        print(batch['features'][:2])\n",
    "        print('--labels--')\n",
    "        print(batch['labels'].shape)\n",
    "        print(batch['labels'][:2])\n",
    "        i += 1\n",
    "        if i >= 2:\n",
    "            break\n",
    "        \n",
    "    group_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MapPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 78)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cnt, n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_rdd = data \\\n",
    "    .coalesce(n_batch, shuffle=True) \\\n",
    "    .zipWithIndex() \\\n",
    "    .map(lambda x: (x[1]%n_batch , x[0])) \\\n",
    "    .groupByKey() \\\n",
    "    .map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.resultiterable.ResultIterable at 0x1075418d0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "def concat_data(it):\n",
    "    dataset = None\n",
    "    for d in it:\n",
    "        if dataset is None:\n",
    "            dataset = d\n",
    "        else:\n",
    "            for f in ['features', 'label']:\n",
    "                dataset[f] = np.concatenate((dataset[f], d[f]), axis=0)\n",
    "    yield dataset\n",
    "\n",
    "for batch in batch_rdd.mapPartitions(concat_data).filter(lambda x: x is not None).collect():\n",
    "    batch = list(batch) # process it!\n",
    "    print(len(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
